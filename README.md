
# Musical Harmony Analysis â€“ README

This project performs MIR-based (Music Information Retrieval) analysis of audio tracks (MP3, M4A/ALAC, FLAC, WAVâ€¦) without relying on any machineâ€‘learning datasets or Spotify Premium.  
Focused on DJâ€‘relevant signal features: rhythmic density, percussive character, tonal center, spectral balance, and transient sharpness.

---

## ðŸŽµ **Analyzed Audio Parameters (Explained Technically)**

Below are all lowâ€‘complexity, fully deterministic DSP metrics extracted from audio in this project.  
Each metric is based on established MIR methods (Essentia, Librosa) and corresponds to DJâ€‘relevant perceptual qualities.

---

## **1. Key (TÃ³nina) & Mode (Major/Minor)**  
**Method:** Essentia `KeyExtractor`  
- Detects global tonal center (e.g., F#, D, Aâ™­).  
- Major/minor classification.  
- `key_strength` indicates model confidence.

**Usage for DJs:** harmonic mixing, Camelot mapping, color-coded grouping.

---

## **2. BPM (Tempo)**  
**Method:** Essentia `RhythmExtractor2013`  
- Robust beat detection using multi-feature estimation.  
- `bpm_confidence` for reliability.

**Usage:** verifying tempo, detecting problematic files (rips, edits).

---

## **3. RMS Energy**  
**What it represents:** raw physical energy of the waveform.

**Why it matters:** correlates with perceived punch, but does not equal loudness.  
Useful as a neutral, gainâ€‘independent baseline.

Parameters:
- `rms_mean`  
- `rms_std`

---

## **4. Percussive Ratio (HPSS)**  
**Method:** Harmonicâ€“Percussive Source Separation  
Measures how much of the signal consists of *transients / drum hits* vs *pads / harmonic content*.

- High â†’ techno, electro, energetic bangers  
- Low â†’ deep house, ambient, grooveâ€‘light tracks

Parameter:
- `percussive_ratio`

---

## **5. Onset Density (Rhythmic Density)**  
**Meaning:** counts how many transient events per second occur.

This reliably captures:
- **1/8 hats** (high onset density â†’ energetic feel)  
- **1/4 hats** (lower density â†’ drop in groove)

Parameter:
- `onset_rate`

---

## **6. Spectral Centroid (â€œBrightnessâ€)**  
**Meaning:** where the â€œcenter of massâ€ of spectral energy lies.  
Bright = sizzle, fizz, highs.  
Dark = warm, muted, deep.

Parameters:
- `centroid_mean`  
- `centroid_std`

---

## **7. Spectral Flux (â€œTransient Activityâ€)**  
How much the spectrum changes frameâ€‘toâ€‘frame.  
Tracks with strong percussion have high flux.

Parameters:
- `flux_mean`
- `flux_std`

---

## **8. High-Frequency Ratio (>= 6 kHz)**  
A proxy for the **hi-hat / shimmer layer**.

- High â†’ crisp top end, energetic hats  
- Low â†’ muffled, soft, padâ€‘driven

Parameter:
- `hf_ratio`

---

## **9. Bass Ratio (< 200 Hz)**  
Measures lowâ€‘end dominance.

- Useful to identify tracks with strong sub/bass  
- Helps characterize balance (subâ€‘heavy vs midâ€‘heavy tracks)

Parameter:
- `bass_ratio`

---

## **10. Attack Sharpness**  
Derived from the slope of the onset envelope.  
Captures how â€œhardâ€ the transient attacks are.

- High â†’ electro/techno punchy kicks  
- Low â†’ deep house smooth edges

Parameter:
- `attack_sharpness`

---

# ðŸ“ˆ Output Format  
All results are saved to:

```
analysis.csv
```

Each row = one track, columns = above features.

---

# ðŸ“‚ Directory Structure

```
MusicalHarmonyAnalysis/
 â”œâ”€â”€ music/           # put audio files here
 â”œâ”€â”€ analyse_music.py
 â”œâ”€â”€ analysis.csv     # output
 â”œâ”€â”€ .venv/           # uv environment
 â””â”€â”€ run.sh           # bootstrap / execution
```

---

# ðŸ—‚ï¸ TODO / Optional Extensions

### **1. Camelot Key Mapping**  
Convert keys (e.g., F# minor â†’ 11A) for harmonic mixing.

### **2. DJ Energy Index (combined metric)**  
Composite index using:
- percussive_ratio  
- onset_rate  
- hf_ratio  
- attack_sharpness  

### **3. Transition Compatibility Scoring**  
Quantify how two tracks blend based on:
- key distance  
- rhythmic density match  
- spectral balance similarity

### **4. Heatmaps & Visualization Tools**  
- brightness vs. bass ratio  
- groove density maps  
- clustering based on audio features

### **5. Spotify Audio Feature Fallback**  
If a track exists on Spotify:
- fetch MLâ€‘derived features (danceability, valenceâ€¦)  
- merge with local DSP metrics  
(No Spotify Premium required for these endpoints.)

---

# ðŸ§ª Notes on Audio Processing

- All audio is decoded on-the-fly (MP3, M4A/ALAC, FLAC, WAV, AAC).  
- Sampling rate is automatically resampled to 44.1 kHz.  
- Bit depth does not matter (16/24/32 float â†’ normalized internally).  
- Stereo mix â†’ mono for stable analysis.

---

# âœ” Summary

This project extracts **real, deterministic, DSP-based audio descriptors** that directly correlate with DJâ€‘perceived musical properties:
- tonal center  
- rhythmic density  
- transient sharpness  
- spectral balance  
- percussive dominance

These form a robust baseline for further energy models, compatibility scoring, and integration with Spotify data if desired.

